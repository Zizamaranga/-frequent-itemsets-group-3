{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76751560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Transaction\n",
      "0  Butter, Milk, Soap, Beef, Chicken, Toothpaste,...\n",
      "1    Butter, Peas, Soap, Onions, Eggs, Lettuce, Rice\n",
      "2                                         Milk, Eggs\n",
      "3                         Chicken, Potatoes, Carrots\n",
      "4                                    Onions, Bananas\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd # Data manipulation library\n",
    "import random \n",
    "\n",
    "# Defining a pool of 30 unique supermarket items\n",
    "item_pool = [ # List of items available in the supermarket\n",
    "    'Milk', 'Bread', 'Eggs', 'Butter', 'Cheese', 'Apples', 'Bananas', 'Chicken',\n",
    "    'Beef', 'Fish', 'Yogurt', 'Juice', 'Cereal', 'Rice', 'Pasta', 'Tomatoes',\n",
    "    'Potatoes', 'Onions', 'Lettuce', 'Carrots', 'Beans', 'Peas', 'Toilet Paper',\n",
    "    'Soap', 'Shampoo', 'Toothpaste', 'Water', 'Soda', 'Coffee', 'Tea'\n",
    "] # A list of items to simulate transactions\n",
    "\n",
    "# Setting a random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Generating 3000 transactions with 2â€“7 random items each\n",
    "transactions = []\n",
    "for _ in range(3000):\n",
    "    num_items = random.randint(2, 7)\n",
    "    transaction = random.sample(item_pool, num_items)\n",
    "    transactions.append(', '.join(transaction))  # Join items into a comma-separated string\n",
    "\n",
    "# Saving transactions to CSV\n",
    "df_transactions = pd.DataFrame({'Transaction': transactions})\n",
    "df_transactions.to_csv('supermarket_transactions.csv', index=False)\n",
    "\n",
    "# Preview first 5 transactions\n",
    "print(df_transactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29297984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Frequent Itemsets:\n",
      "        itemsets   support\n",
      "18          Peas  0.170000\n",
      "5         Butter  0.162333\n",
      "26      Tomatoes  0.161000\n",
      "2          Beans  0.159333\n",
      "8         Cheese  0.159000\n",
      "25  Toilet Paper  0.156667\n",
      "20          Rice  0.154333\n",
      "22          Soap  0.154000\n",
      "17         Pasta  0.154000\n",
      "7         Cereal  0.152667\n",
      "\n",
      "Top 10 frequent itemsets exported to 'top_10_frequent_itemsets.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import csv\n",
    "\n",
    "# Load the transactions from the CSV file generated previously\n",
    "df_transactions = pd.read_csv('supermarket_transactions.csv')\n",
    "\n",
    "# Convert transactions to a list of lists (split comma-separated strings)\n",
    "# Each transaction is a list of items, e.g., ['Milk', 'Bread', 'Eggs']\n",
    "transactions = [trans.split(', ') for trans in df_transactions['Transaction']]\n",
    "\n",
    "# Get the total number of transactions for support calculations\n",
    "total_transactions = len(transactions)\n",
    "\n",
    "# Define the minimum support threshold (5% of transactions)\n",
    "min_support = 0.05\n",
    "\n",
    "# Helper function to get all unique items in the dataset\n",
    "def get_unique_items(transactions):\n",
    "    # Create a set of all unique items across all transactions\n",
    "    unique_items = set()\n",
    "    for trans in transactions:\n",
    "        unique_items.update(trans)\n",
    "    return sorted(unique_items)  # Return sorted list for consistency\n",
    "\n",
    "# Helper function to calculate support for a given itemset\n",
    "def calculate_support(itemset, transactions):\n",
    "    # Count how many transactions contain the itemset\n",
    "    count = sum(1 for trans in transactions if set(itemset).issubset(set(trans)))\n",
    "    # Return support as a fraction of total transactions\n",
    "    return count / total_transactions\n",
    "\n",
    "# Helper function to generate candidate itemsets of size k\n",
    "def generate_candidates(prev_frequent, k):\n",
    "    # Generate all possible k-itemsets from (k-1)-itemsets\n",
    "    candidates = []\n",
    "    for i in range(len(prev_frequent)):\n",
    "        for j in range(i + 1, len(prev_frequent)):\n",
    "            # Ensure itemsets can be combined (first k-2 items match)\n",
    "            if k == 2 or prev_frequent[i][:-1] == prev_frequent[j][:-1]:\n",
    "                # Combine two (k-1)-itemsets to form a k-itemset\n",
    "                new_candidate = tuple(sorted(set(prev_frequent[i]) | set(prev_frequent[j])))\n",
    "                if len(new_candidate) == k:\n",
    "                    candidates.append(new_candidate)\n",
    "    return candidates\n",
    "\n",
    "# Custom Apriori algorithm implementation\n",
    "def apriori(transactions, min_support):\n",
    "    # Initialize frequent itemsets dictionary to store results\n",
    "    frequent_itemsets = []\n",
    "    \n",
    "    # Step 1: Generate 1-itemsets\n",
    "    unique_items = get_unique_items(transactions)\n",
    "    # Calculate support for each single item\n",
    "    itemsets_1 = [(item,) for item in unique_items]\n",
    "    frequent_1 = [(itemset, calculate_support(itemset, transactions)) \n",
    "                  for itemset in itemsets_1 if calculate_support(itemset, transactions) >= min_support]\n",
    "    frequent_itemsets.extend(frequent_1)\n",
    "    \n",
    "    # Step 2: Generate k-itemsets iteratively\n",
    "    k = 2\n",
    "    prev_frequent = [itemset for itemset, _ in frequent_1]\n",
    "    \n",
    "    while prev_frequent:\n",
    "        # Generate candidate k-itemsets\n",
    "        candidates = generate_candidates(prev_frequent, k)\n",
    "        # Calculate support for each candidate\n",
    "        frequent_k = [(itemset, calculate_support(itemset, transactions)) \n",
    "                      for itemset in candidates if calculate_support(itemset, transactions) >= min_support]\n",
    "        # Add frequent k-itemsets to results\n",
    "        frequent_itemsets.extend(frequent_k)\n",
    "        # Prepare for next iteration\n",
    "        prev_frequent = [itemset for itemset, _ in frequent_k]\n",
    "        k += 1\n",
    "    \n",
    "    return frequent_itemsets\n",
    "\n",
    "# Run Apriori algorithm to get frequent itemsets\n",
    "frequent_itemsets = apriori(transactions, min_support)\n",
    "\n",
    "# Convert to DataFrame for sorting and display\n",
    "# Format itemsets as strings for readability\n",
    "frequent_itemsets_df = pd.DataFrame(frequent_itemsets, columns=['itemsets', 'support'])\n",
    "frequent_itemsets_df['itemsets'] = frequent_itemsets_df['itemsets'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Sort by support in descending order and get top 10\n",
    "top_10_itemsets = frequent_itemsets_df.sort_values(by='support', ascending=False).head(10)\n",
    "\n",
    "# Display the top 10 frequent itemsets\n",
    "print(\"Top 10 Frequent Itemsets:\")\n",
    "print(top_10_itemsets)\n",
    "\n",
    "# Export the top 10 itemsets to a CSV file\n",
    "top_10_itemsets.to_csv('top_10_frequent_itemsets.csv', index=False)\n",
    "print(\"\\nTop 10 frequent itemsets exported to 'top_10_frequent_itemsets.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3fec6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Frequent Itemsets:\n",
      "        itemsets   support\n",
      "0         Apples  0.146000\n",
      "1        Bananas  0.144333\n",
      "2          Beans  0.159333\n",
      "3           Beef  0.136667\n",
      "4          Bread  0.147000\n",
      "5         Butter  0.162333\n",
      "6        Carrots  0.147667\n",
      "7         Cereal  0.152667\n",
      "8         Cheese  0.159000\n",
      "9        Chicken  0.143667\n",
      "10        Coffee  0.139333\n",
      "11          Eggs  0.152000\n",
      "12          Fish  0.152667\n",
      "13         Juice  0.145000\n",
      "14       Lettuce  0.146667\n",
      "15          Milk  0.141333\n",
      "16        Onions  0.152333\n",
      "17         Pasta  0.154000\n",
      "18          Peas  0.170000\n",
      "19      Potatoes  0.141333\n",
      "20          Rice  0.154333\n",
      "21       Shampoo  0.146667\n",
      "22          Soap  0.154000\n",
      "23          Soda  0.142000\n",
      "24           Tea  0.145000\n",
      "25  Toilet Paper  0.156667\n",
      "26      Tomatoes  0.161000\n",
      "27    Toothpaste  0.144000\n",
      "28         Water  0.145333\n",
      "29        Yogurt  0.150333\n"
     ]
    }
   ],
   "source": [
    "# [Student: Ziza \n",
    "# 4. Identify Closed Frequent Itemsets]\n",
    "import pandas as pd\n",
    "\n",
    "# Identify closed frequent itemsets\n",
    "closed_itemsets = []\n",
    "\n",
    "# Convert frequent_itemsets to a dict for fast support lookup\n",
    "support_lookup = dict(frequent_itemsets)\n",
    "\n",
    "# For each itemset, check if there is any proper superset in frequent_itemsets with the same support\n",
    "for itemset, support in frequent_itemsets:\n",
    "    is_closed = True\n",
    "    for other_itemset, other_support in frequent_itemsets:\n",
    "        # Check if other_itemset is a proper superset and has the same support\n",
    "        if set(itemset) < set(other_itemset) and support == other_support:\n",
    "            is_closed = False\n",
    "            break\n",
    "    if is_closed:\n",
    "        closed_itemsets.append((itemset, support))\n",
    "\n",
    "# Convert to DataFrame for display and export\n",
    "\n",
    "closed_itemsets_df = pd.DataFrame(closed_itemsets, columns=['itemsets', 'support'])\n",
    "closed_itemsets_df['itemsets'] = closed_itemsets_df['itemsets'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Export to CSV\n",
    "closed_itemsets_df.to_csv('closed_itemsets.csv', index=False)\n",
    "\n",
    "# Display the closed frequent itemsets\n",
    "print(\"Closed Frequent Itemsets:\")\n",
    "print(closed_itemsets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52234ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximal Frequent Itemsets:\n",
      "        itemsets   support\n",
      "18          Peas  0.170000\n",
      "5         Butter  0.162333\n",
      "26      Tomatoes  0.161000\n",
      "2          Beans  0.159333\n",
      "8         Cheese  0.159000\n",
      "25  Toilet Paper  0.156667\n",
      "20          Rice  0.154333\n",
      "22          Soap  0.154000\n",
      "17         Pasta  0.154000\n",
      "7         Cereal  0.152667\n",
      "12          Fish  0.152667\n",
      "16        Onions  0.152333\n",
      "11          Eggs  0.152000\n",
      "29        Yogurt  0.150333\n",
      "6        Carrots  0.147667\n",
      "4          Bread  0.147000\n",
      "21       Shampoo  0.146667\n",
      "14       Lettuce  0.146667\n",
      "0         Apples  0.146000\n",
      "28         Water  0.145333\n",
      "13         Juice  0.145000\n",
      "24           Tea  0.145000\n",
      "1        Bananas  0.144333\n",
      "27    Toothpaste  0.144000\n",
      "9        Chicken  0.143667\n",
      "23          Soda  0.142000\n",
      "19      Potatoes  0.141333\n",
      "15          Milk  0.141333\n",
      "10        Coffee  0.139333\n",
      "3           Beef  0.136667\n",
      "\n",
      "Maximal frequent itemsets exported to 'maximal_frequent_itemsets.csv'\n"
     ]
    }
   ],
   "source": [
    "# Identifying maximal frequent itemsets\n",
    "\n",
    "def is_maximal(itemset, itemset_support, all_frequent_dict):\n",
    "    \"\"\"\n",
    "    Check if an itemset is maximal by verifying no frequent superset exists.\n",
    "    \"\"\"\n",
    "    itemset_set = set(itemset)\n",
    "    for other in all_frequent_dict:\n",
    "        other_set = set(other)\n",
    "        if len(other_set) > len(itemset_set) and itemset_set.issubset(other_set):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Convert list of tuples into dictionary for fast lookup\n",
    "all_frequent_dict = {itemset: support for itemset, support in frequent_itemsets}\n",
    "\n",
    "# Find maximal itemsets\n",
    "maximal_itemsets = []\n",
    "for itemset, support in frequent_itemsets:\n",
    "    if is_maximal(itemset, support, all_frequent_dict):\n",
    "        maximal_itemsets.append((itemset, support))\n",
    "\n",
    "# Convert to DataFrame\n",
    "maximal_df = pd.DataFrame(maximal_itemsets, columns=[\"itemsets\", \"support\"])\n",
    "maximal_df[\"itemsets\"] = maximal_df[\"itemsets\"].apply(lambda x: \", \".join(x))\n",
    "maximal_df = maximal_df.sort_values(by=\"support\", ascending=False)\n",
    "\n",
    "# Print result\n",
    "print(\"\\nMaximal Frequent Itemsets:\")\n",
    "print(maximal_df)\n",
    "\n",
    "# Export to CSV\n",
    "maximal_df.to_csv(\"maximal_frequent_itemsets.csv\", index=False)\n",
    "print(\"\\nMaximal frequent itemsets exported to 'maximal_frequent_itemsets.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
